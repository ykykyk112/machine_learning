{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-07524ecf0319>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m ])\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrain_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCIFAR10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mtest_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCIFAR10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_integrity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Files already downloaded and verified'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0mdownload_and_extract_archive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtgz_md5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36mdownload_and_extract_archive\u001b[0;34m(url, download_root, extract_root, filename, md5, remove_finished)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m     \u001b[0mdownload_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m     \u001b[0marchive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownload_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36mdownload_url\u001b[0;34m(url, root, filename, md5, max_redirect_hops)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;31m# expand redirect chain if needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m     \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_redirect_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_hops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_redirect_hops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;31m# check if file is located on Google Drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36m_get_redirect_url\u001b[0;34m(url, max_hops)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhop\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_hops\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0murl\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    540\u001b[0m         }\n\u001b[1;32m    541\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m             \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/requests/models.py\u001b[0m in \u001b[0;36mcontent\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    829\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 831\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mb''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCONTENT_CHUNK_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34mb''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_content_consumed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/requests/models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    751\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'stream'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 753\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    754\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    574\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_fp_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m                 \u001b[0mcache_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfp_closed\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m                 if (\n\u001b[1;32m    521\u001b[0m                     \u001b[0mamt\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0;31m# Amount is given, implement using readinto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;31m# connection, and the user is reading more bytes than will be provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;31m# (for example, reading in 1k chunks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m             \u001b[0;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1239\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1241\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1242\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1097\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Normalize(mean = (0.5, 0.5, 0.5), std = (0.5, 0.5, 0.5))\n",
    "    transforms.Normalize(mean = 0.5, std = 0.5)\n",
    "])\n",
    "\n",
    "train_set = datasets.CIFAR10('./data', download = True, train = True, transform = transform)\n",
    "test_set = datasets.CIFAR10('./data', download = True, train = False, transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, shuffle = True, batch_size = 50, num_workers = 2)\n",
    "test_loader = DataLoader(test_set, shuffle = False, batch_size = 50, num_workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simple_Net(nn.Module) :\n",
    "    def __init__(self):\n",
    "        super(Simple_Net, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Linear(784, 512), nn.ReLU(),\n",
    "            nn.Linear(512, 256), nn.ReLU(),\n",
    "            nn.Linear(256, 100), nn.ReLU(),\n",
    "            nn.Linear(100, 10)\n",
    "        )\n",
    "        self.initialize_weight()\n",
    "        \n",
    "    def initialize_weight(self):\n",
    "        for m in self.modules() :\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                m.bias.data.zero_()\n",
    "                \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        out = self.features(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(0)\n",
    "net = Simple_Net()\n",
    "net.load_state_dict(torch.load('./Simple_Net.pth'))\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-167b3736afd7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(net.parameters(), lr = 0.01)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=4, gamma=0.1)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "for i in range(12):\n",
    "    train_loss, train_acc = 0.0, 0.0\n",
    "    valid_loss, valid_acc = 0.0, 0.0\n",
    "    \n",
    "    for image, label in train_loader:\n",
    "        net.train()\n",
    "        image, label = image.to(device), label.to(device)\n",
    "        \n",
    "        output = net.forward(image)\n",
    "        t_loss = loss(output, label)\n",
    "        optimizer.zero_grad()\n",
    "        t_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        _, pred = torch.max(output, dim = 1)\n",
    "        \n",
    "        train_loss += t_loss.item()\n",
    "        train_acc += torch.sum(pred==label.data)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for v_image, v_label in test_loader:\n",
    "            \n",
    "            net.eval()\n",
    "            \n",
    "            v_image, v_label = v_image.to(device), v_label.to(device)\n",
    "            \n",
    "            v_output = net.forward(v_image)\n",
    "            v_loss = loss(v_output, v_label)\n",
    "            \n",
    "            _, v_pred = torch.max(v_output, dim = 1)\n",
    "            \n",
    "            valid_loss += v_loss.item()\n",
    "            valid_acc += torch.sum(v_pred==v_label.data)\n",
    "            \n",
    "    curr_lr = optimizer.param_groups[0]['lr']\n",
    "    scheduler.step()\n",
    "    \n",
    "    train_acc = train_acc*(100/image.size()[0])\n",
    "    valid_acc = valid_acc*(100/v_image.size()[0])\n",
    "\n",
    "    avg_train_loss = train_loss/len(train_loader)\n",
    "    avg_valid_loss = valid_loss/len(test_loader)\n",
    "    avg_train_acc = train_acc/len(train_loader)\n",
    "    avg_valid_acc = valid_acc/len(test_loader)\n",
    "            \n",
    "    print('epoch.{0:3d} \\t train_ls : {1:.6f} \\t train_ac : {2:.4f}% \\t valid_ls : {3:.6f} \\t valid_ac : {4:.4f}% \\t lr : {5:.6f}'.format(i+1, avg_train_loss, avg_train_acc, avg_valid_loss, avg_valid_acc, curr_lr))        \n",
    "\n",
    "path = './Simple_Net.pth'\n",
    "torch.save(net.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relprop(activation, layer, R):\n",
    "    \n",
    "    if activation.requires_grad == False:\n",
    "        activation.requires_grad = True\n",
    "        \n",
    "    z = layer.forward(activation)\n",
    "    s = R/(z+1e-9)\n",
    "    (z*s.data).sum().backward()\n",
    "    c = activation.grad\n",
    "    return activation*c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LRP():\n",
    "    def __init__(self, model, module_list, device):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.module_list = tuple(module_list)\n",
    "        self.model_layers = []\n",
    "        self.model_activation = []\n",
    "        self.hook_history = []\n",
    "        self.set_layer()\n",
    "        self.register_hook()\n",
    "  \n",
    "    # Initializing network's modules, which used in backward propagation(nn.Linear or nn.Conv2d or nn.AvgPool2d)\n",
    "    def set_layer(self):\n",
    "        module = list(self.model.modules())\n",
    "        module.reverse()\n",
    "        for m in module:\n",
    "            if isinstance(m, self.module_list):\n",
    "                m.bias.data.zero_()\n",
    "                self.model_layers.append(m)\n",
    "    \n",
    "    # Forward hook to get activation value after each ReLU function\n",
    "    def forward_hook(self, _, image, output):\n",
    "        self.model_activation.append(output)\n",
    "    \n",
    "    def register_hook(self) :\n",
    "        for m in self.model.modules():\n",
    "            if isinstance(m, nn.ReLU):\n",
    "                hook = m.register_forward_hook(self.forward_hook)\n",
    "                self.hook_history.append(hook)\n",
    "                \n",
    "    def remove_hook(self) :\n",
    "        for h in self.hook_history:\n",
    "            h.remove()\n",
    "        self.hook_history = []\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.model_activation = []\n",
    "        self.model_activation.append(x.view(x.size(0), -1))\n",
    "        with torch.no_grad():\n",
    "            self.model.eval()\n",
    "            ret = self.model.forward(x).data\n",
    "            self.model_activation.reverse()\n",
    "        return ret\n",
    "                \n",
    "    def rho(self, layer, rule, gamma = None) :\n",
    "        with torch.no_grad():\n",
    "            if rule == 'gamma' :\n",
    "                l = copy.deepcopy(layer)\n",
    "                pos_idx = torch.where(l.weight>0)\n",
    "                l.weight[pos_idx] += l.weight[pos_idx]*gamma\n",
    "                return l\n",
    "        \n",
    "            elif rule == 'zero' :\n",
    "                return layer\n",
    "        \n",
    "    def relprop(self, activation, layer, R, eps = None, rule = 'zero', batch = False):\n",
    "        \n",
    "        #if not batch : activation = activation.squeeze(0)\n",
    "        epsilon = 0.\n",
    "        if eps != None : epsilon = eps\n",
    "        \n",
    "        if not activation.requires_grad:\n",
    "            activation.requires_grad = True\n",
    "        \n",
    "        z = epsilon + self.rho(layer, rule).forward(activation)\n",
    "        s = R/(z+1e-9)\n",
    "        (z*s.data).sum().backward()\n",
    "        c = activation.grad\n",
    "        return activation*c\n",
    "    \n",
    "    def relprop_ws(self, layer, R):\n",
    "        print('R :', R.shape)\n",
    "        w_s = (layer.weight*layer.weight)\n",
    "        print('w_s :', w_s.shape)\n",
    "        z = w_s.sum(dim = 1)\n",
    "        print('z :', z.shape)\n",
    "        s = (R/(z+1e-9))\n",
    "        print('s :', s.shape)\n",
    "        R_p = s.matmul(w_s)\n",
    "        print('R_p :', R_p.shape)\n",
    "        return R_p\n",
    "    \n",
    "    def relprop_zb(self, layer, R):\n",
    "        x = self.model_activation[-1].clone()\n",
    "        l = torch.full(tuple(x.shape), x.min()).to(device)\n",
    "        h = torch.full(tuple(x.shape), x.max()).to(device)\n",
    "        f_p = copy.deepcopy(layer)\n",
    "        f_n = copy.deepcopy(layer)\n",
    "        with torch.no_grad():\n",
    "            f_p.weight[torch.where(f_p.weight<0)] = 0.\n",
    "            f_n.weight[torch.where(f_n.weight>0)] = 0.\n",
    "        x.requires_grad = True\n",
    "        l.requires_grad = True\n",
    "        h.requires_grad = True\n",
    "        z = layer.forward(x)-f_p.forward(l)-f_n.forward(h)\n",
    "        s = R/(z+1e-9)\n",
    "        (z*s.data).sum().backward()\n",
    "        return x*x.grad+l*l.grad+h*h.grad\n",
    "    \n",
    "    def get_relevance(self, image):\n",
    "        output = self.forward(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrp = LRP(net, [nn.Linear, nn.Conv2d, nn.MaxPool2d], device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Linear(in_features=100, out_features=10, bias=True),\n",
       " Linear(in_features=256, out_features=100, bias=True),\n",
       " Linear(in_features=512, out_features=256, bias=True),\n",
       " Linear(in_features=784, out_features=512, bias=True)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrp.model_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = iter(test_loader).next()\n",
    "image, label = image.to(device), label.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 1, 28, 28])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrp.model_activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 10])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = lrp.forward(image)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 100])\n",
      "torch.Size([50, 256])\n",
      "torch.Size([50, 512])\n",
      "torch.Size([50, 784])\n"
     ]
    }
   ],
   "source": [
    "for i in lrp.model_activation:\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7, 2, 1, 0, 4, 1, 4, 9, 6, 9, 0, 6, 9, 0, 1, 5, 9, 7, 3, 4, 9, 6, 6, 5,\n",
      "        4, 0, 7, 4, 0, 1, 3, 1, 3, 4, 7, 2, 7, 1, 2, 1, 1, 7, 4, 2, 3, 5, 1, 2,\n",
      "        4, 4], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([50])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, pred = torch.max(output, dim = 1)\n",
    "print(pred)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, 11.1899,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  9.8503,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000, 13.9843,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 7.9986,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  7.9318,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000, 14.3157,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000, 10.2785,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  7.7127],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  9.3134,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  8.8434],\n",
      "        [ 9.3491,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, 12.1230,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000, 12.7517],\n",
      "        [11.9582,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000, 16.8796,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000, 15.0018,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000, 10.7245],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  8.9133,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  6.1374,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000, 10.4307,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000, 10.2398],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, 17.8152,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, 10.6333,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000, 22.9754,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  8.5486,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [12.9642,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, 11.4212,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  9.8695,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 8.0293,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000, 13.4290,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000, 20.0895,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000, 12.1047,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000, 18.7486,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  9.2052,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, 13.8053,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  7.1074,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  7.4344,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000, 14.9147,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  5.4280,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000, 16.4475,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000, 11.7647,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, 10.6994,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000, 11.3547,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  7.9747,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  8.6397,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000, 12.9144,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  9.3965,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000, 11.5729,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000, 14.6357,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  9.6425,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000]], device='cuda:0')\n",
      "torch.Size([50, 10])\n"
     ]
    }
   ],
   "source": [
    "out = torch.full((50, 10), 0.).to(device)\n",
    "for i in range(50):\n",
    "    out[i][pred[i]] = output[i][pred[i]]\n",
    "# out[0][pred] = output[0][pred]\n",
    "print(out)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 100])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R = lrp.relprop(lrp.model_activation[0], lrp.model_layers[0], out)\n",
    "R.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11.1899,  9.8503, 13.9843,  7.9986,  7.9318, 14.3157, 10.2785,  7.7127,\n",
       "         9.3134,  8.8434,  9.3491, 12.1230, 12.7517, 11.9582, 16.8796, 15.0018,\n",
       "        10.7245,  8.9133,  6.1374, 10.4307, 10.2398, 17.8152, 10.6333, 22.9754,\n",
       "         8.5486, 12.9642, 11.4212,  9.8695,  8.0293, 13.4290, 20.0895, 12.1047,\n",
       "        18.7486,  9.2052, 13.8053,  7.1074,  7.4344, 14.9147,  5.4280, 16.4475,\n",
       "        11.7647, 10.6994, 11.3547,  7.9747,  8.6397, 12.9144,  9.3965, 11.5729,\n",
       "        14.6357,  9.6425], device='cuda:0', grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R.sum(dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([11.1898,  9.8503, 13.9843,  7.9986,  7.9318, 14.3157, 10.2785,  7.7127,\n",
      "         9.3134,  8.8434,  9.3491, 12.1230, 12.7517, 11.9582, 16.8796, 15.0018,\n",
      "        10.7245,  8.9133,  6.1374, 10.4307, 10.2398, 17.8152, 10.6333, 22.9754,\n",
      "         8.5486, 12.9642, 11.4212,  9.8695,  8.0293, 13.4290, 20.0895, 12.1047,\n",
      "        18.7486,  9.2052, 13.8053,  7.1074,  7.4344, 14.9147,  5.4280, 16.4475,\n",
      "        11.7647, 10.6994, 11.3547,  7.9747,  8.6397, 12.9144,  9.3965, 11.5729,\n",
      "        14.6357,  9.6425], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([50, 256])\n"
     ]
    }
   ],
   "source": [
    "R_1 = lrp.relprop(lrp.model_activation[1], lrp.model_layers[1], R)\n",
    "print(R_1.sum(dim = 1))\n",
    "print(R_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([11.1899,  9.8503, 13.9843,  7.9986,  7.9318, 14.3157, 10.2785,  7.7127,\n",
      "         9.3134,  8.8434,  9.3491, 12.1230, 12.7517, 11.9582, 16.8796, 15.0018,\n",
      "        10.7245,  8.9133,  6.1374, 10.4307, 10.2398, 17.8152, 10.6333, 22.9754,\n",
      "         8.5486, 12.9642, 11.4212,  9.8695,  8.0293, 13.4290, 20.0895, 12.1047,\n",
      "        18.7486,  9.2052, 13.8053,  7.1074,  7.4344, 14.9147,  5.4280, 16.4475,\n",
      "        11.7647, 10.6994, 11.3547,  7.9747,  8.6397, 12.9144,  9.3965, 11.5729,\n",
      "        14.6357,  9.6425], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "torch.Size([50, 512])\n"
     ]
    }
   ],
   "source": [
    "R_2 = lrp.relprop(lrp.model_activation[2], lrp.model_layers[2], R_1)\n",
    "print(R_2.sum(dim = 1))\n",
    "print(R_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R : torch.Size([50, 512])\n",
      "w_s : torch.Size([512, 784])\n",
      "z : torch.Size([512])\n",
      "s : torch.Size([50, 512])\n",
      "R_p : torch.Size([50, 784])\n"
     ]
    }
   ],
   "source": [
    "R_zb = lrp.relprop_zb(lrp.model_layers[3], R_2)\n",
    "R_ws = lrp.relprop_ws(lrp.model_layers[3], R_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11.1899,  9.8503, 13.9843,  7.9986,  7.9318, 14.3157, 10.2785,  7.7127,\n",
       "         9.3134,  8.8434,  9.3491, 12.1230, 12.7517, 11.9582, 16.8796, 15.0018,\n",
       "        10.7245,  8.9133,  6.1374, 10.4307, 10.2398, 17.8152, 10.6333, 22.9754,\n",
       "         8.5486, 12.9642, 11.4212,  9.8695,  8.0293, 13.4290, 20.0895, 12.1047,\n",
       "        18.7486,  9.2052, 13.8053,  7.1074,  7.4344, 14.9147,  5.4280, 16.4475,\n",
       "        11.7647, 10.6994, 11.3547,  7.9747,  8.6397, 12.9144,  9.3965, 11.5729,\n",
       "        14.6357,  9.6425], device='cuda:0', grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_ws.sum(dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11.1899,  9.8503, 13.9843,  7.9986,  7.9318, 14.3157, 10.2785,  7.7127,\n",
       "         9.3134,  8.8434,  9.3491, 12.1230, 12.7517, 11.9582, 16.8796, 15.0018,\n",
       "        10.7245,  8.9133,  6.1374, 10.4307, 10.2398, 17.8152, 10.6333, 22.9754,\n",
       "         8.5486, 12.9642, 11.4212,  9.8695,  8.0293, 13.4290, 20.0895, 12.1047,\n",
       "        18.7486,  9.2052, 13.8053,  7.1074,  7.4344, 14.9147,  5.4280, 16.4475,\n",
       "        11.7647, 10.6994, 11.3547,  7.9747,  8.6397, 12.9144,  9.3965, 11.5729,\n",
       "        14.6357,  9.6425], device='cuda:0', grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_zb.sum(dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 784])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_ws.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = image[11]\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1049,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x250200d9a30>"
      ]
     },
     "execution_count": 1049,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAOZ0lEQVR4nO3df6xU9ZnH8c+jlj+0mKBcDYIr3Qr+iIkUJoTAptHgEn8k/NDYlBjCGswl/kha4Y81XUmNEmPMlkbNBr38SNlNV2zSqkSM1mATU0XCCKxiSZU1SG+5whA1SEzsYp/94x7MFe58z2XOmTkDz/uVTGbmPHPmPI73w5mZ7znzNXcXgDPfWVU3AKAzCDsQBGEHgiDsQBCEHQjinE5ubOzYsT5x4sRObhIIZd++fTp8+LANVysUdjO7UdITks6WtNbdH0s9fuLEiarX60U2CSChVqs1rbX8Nt7Mzpb0H5JuknS1pIVmdnWrzwegvYp8Zp8uaa+7f+Tuf5O0UdK8ctoCULYiYR8v6S9D7vdny77FzHrNrG5m9UajUWBzAIooEvbhvgQ46dhbd+9z95q713p6egpsDkARRcLeL+nSIfcnSDpQrB0A7VIk7NslTTKz75nZKEk/lrSpnLYAlK3loTd3P2Zm90l6VYNDb+vd/f3SOgNQqkLj7O7+sqSXS+oFQBtxuCwQBGEHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0F09Kek0ZqvvvoqWZ85c2bT2s6dO5Przp07N1l/4YUXknWcPtizA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQjLN3gbxx9Pvvvz9Z37VrV9Oa2bCz935j2rRpyTrOHOzZgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIxtm7wJNPPpmsP/PMM8n67Nmzm9Yefvjh5LozZsxI1nHmKBR2M9sn6QtJX0s65u61MpoCUL4y9uzXu/vhEp4HQBvxmR0IomjYXdLvzewdM+sd7gFm1mtmdTOrNxqNgpsD0KqiYZ/l7lMl3STpXjP74YkPcPc+d6+5e62np6fg5gC0qlDY3f1Adn1I0vOSppfRFIDytRx2MzvPzEYfvy1pjqTdZTUGoFxFvo2/WNLz2fnS50j6b3d/pZSughkYGCi0/g033NC0xjg6jms57O7+kaRrS+wFQBsx9AYEQdiBIAg7EARhB4Ig7EAQnOLaBY4ePZqsjxo1KllPDb0Bx7FnB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgGGfvgAMHDiTra9euTdZnzpyZrE+dOvWUe0I87NmBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjG2Ttg5cqVVbdwWtq6dWuy3t/f3/JzX3tt+oeRJ0+e3PJzdyv27EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBOPsHbB58+ZC6991110lddJ5d999d9Na3uvy2WefJetffvllSz1J0vnnn5+sL1u2LFlfsWJFy9uuSu6e3czWm9khM9s9ZNkFZvaamX2YXY9pb5sAihrJ2/hfSbrxhGUPSNri7pMkbcnuA+hiuWF39zckfXrC4nmSNmS3N0iaX25bAMrW6hd0F7v7gCRl1xc1e6CZ9ZpZ3czqjUajxc0BKKrt38a7e5+719y91tPT0+7NAWii1bAfNLNxkpRdHyqvJQDt0GrYN0lanN1eLOnFctoB0C7m7ukHmD0r6TpJYyUdlPRzSS9I+o2kf5C0X9Lt7n7il3gnqdVqXq/Xi3XchfLGey+//PJk/Zxz0oc77N+//5R7Gqljx44l6zt27EjW58+fn6x/8sknTWt5f3t5H/tmzZqVrKd6z3tNx48fn6y/+eabyfpll12WrLdLrVZTvV634Wq5B9W4+8ImpdmFugLQURwuCwRB2IEgCDsQBGEHgiDsQBCc4lqCvCmXDx48mKwvXbq0zHa+JW+66L6+vmT9kUceKbT91BDWokWLkuvec889yfqECRNa6kmS5s6dm6znnX47MDCQrFc19JbCnh0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgmCcvQQ7d+4stP6kSZNK6uRkedNFP/3008m62bBnS35j9uz0yY+rVq1qWrvmmmuS67ZT3mnHZyL27EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBOPsJcg7Z7zdPvjgg6a1jRs3Fnru3t7eZP2JJ55I1keNGlVo+1WZNm1asj516tQOdVIe9uxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EATj7CU4cuRIsp43NXFePc9TTz3VtPb5558n173jjjuS9dWrV7fSUtc7evRosp43jfbpePxA7p7dzNab2SEz2z1k2UNm9lcz25Vdbm5vmwCKGsnb+F9JunGY5b909ynZ5eVy2wJQttywu/sbkj7tQC8A2qjIF3T3mdm72dv8Mc0eZGa9ZlY3s3qj0SiwOQBFtBr21ZK+L2mKpAFJv2j2QHfvc/eau9d6enpa3ByAoloKu7sfdPev3f3vktZIml5uWwDK1lLYzWzckLsLJO1u9lgA3SF3nN3MnpV0naSxZtYv6eeSrjOzKZJc0j5J7Ztg/DSQ99vqRet5UufT5z131efit1Pqv23t2rXJdW+77bay26lcbtjdfeEwi9e1oRcAbcThskAQhB0IgrADQRB2IAjCDgTBKa5ngL6+vqa1t956K7luXv3RRx9N1pcuTY+6Xnjhhcl6O916661Na+eee25y3eXLl5fdTuXYswNBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIyzj1DqdMmBgYEOdnKy1Fj2jh07kuvOnTs3WV+xYkWy/uqrrybrL730UtPa6NGjW15XklauXJms79y5s2ntwQcfTK47Y8aMZP10xJ4dCIKwA0EQdiAIwg4EQdiBIAg7EARhB4JgnH2ELrnkkqa1yZMnJ9f9+OOPk/XXX389Wc87Zzx1bva4ceOa1iRp+/btyXreWPdVV12VrKemjM47Zzzv557zzklPjaXnHT9wJmLPDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBMM5egnXr0pPa3nLLLcn65s2bk/U5c+Yk68uWLWtayxtnz7Nt27ZkPe935VPru3ty3SuuuKLQthcsWJCsR5O7ZzezS83sD2a2x8zeN7OfZMsvMLPXzOzD7HpM+9sF0KqRvI0/Jmm5u18laYake83sakkPSNri7pMkbcnuA+hSuWF39wF335Hd/kLSHknjJc2TtCF72AZJ89vUI4ASnNIXdGY2UdIPJG2TdLG7D0iD/yBIuqjJOr1mVjezeqPRKNgugFaNOOxm9l1Jv5X0U3c/MtL13L3P3WvuXuvp6WmlRwAlGFHYzew7Ggz6r939d9nig2Y2LquPk3SoPS0CKEPu0JuZmaR1kva4+6ohpU2SFkt6LLt+sS0dngYmTJiQrL/yyivJ+vXXX5+sb926NVm//fbbk/WUvOGvwf/97XHnnXcm648//niyXuV00KejkYyzz5K0SNJ7ZrYrW/YzDYb8N2a2RNJ+Sa3/xQFou9ywu/sfJTX75312ue0AaBcOlwWCIOxAEIQdCIKwA0EQdiAITnHtgLzTTN9+++1k/bnnnkvW9+7d27S2Zs2a5LpLlixJ1s86q9j+IPX8V155ZaHnxqlhzw4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQVje+cxlqtVqXq/XO7Y9IJparaZ6vT7sWars2YEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiCI3LCb2aVm9gcz22Nm75vZT7LlD5nZX81sV3a5uf3tAmjVSCaJOCZpubvvMLPRkt4xs9ey2i/d/d/b1x6AsoxkfvYBSQPZ7S/MbI+k8e1uDEC5Tukzu5lNlPQDSduyRfeZ2btmtt7MxjRZp9fM6mZWbzQaxboF0LIRh93Mvivpt5J+6u5HJK2W9H1JUzS45//FcOu5e5+719y91tPTU7xjAC0ZUdjN7DsaDPqv3f13kuTuB939a3f/u6Q1kqa3r00ARY3k23iTtE7SHndfNWT50KlJF0jaXX57AMoykm/jZ0laJOk9M9uVLfuZpIVmNkWSS9onaWkb+gNQkpF8G/9HScP9DvXL5bcDoF04gg4IgrADQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSAIOxCEuXvnNmbWkPTxkEVjJR3uWAOnplt769a+JHprVZm9Xebuw/7+W0fDftLGzeruXqusgYRu7a1b+5LorVWd6o238UAQhB0Iouqw91W8/ZRu7a1b+5LorVUd6a3Sz+wAOqfqPTuADiHsQBCVhN3MbjSzP5vZXjN7oIoemjGzfWb2XjYNdb3iXtab2SEz2z1k2QVm9pqZfZhdDzvHXkW9dcU03olpxit97aqe/rzjn9nN7GxJH0j6Z0n9krZLWujuf+poI02Y2T5JNXev/AAMM/uhpKOS/tPdr8mWPS7pU3d/LPuHcoy7/2uX9PaQpKNVT+OdzVY0bug045LmS/oXVfjaJfr6kTrwulWxZ58uaa+7f+Tuf5O0UdK8Cvroeu7+hqRPT1g8T9KG7PYGDf6xdFyT3rqCuw+4+47s9heSjk8zXulrl+irI6oI+3hJfxlyv1/dNd+7S/q9mb1jZr1VNzOMi919QBr845F0UcX9nCh3Gu9OOmGa8a557VqZ/ryoKsI+3FRS3TT+N8vdp0q6SdK92dtVjMyIpvHulGGmGe8KrU5/XlQVYe+XdOmQ+xMkHaigj2G5+4Hs+pCk59V9U1EfPD6DbnZ9qOJ+vtFN03gPN824uuC1q3L68yrCvl3SJDP7npmNkvRjSZsq6OMkZnZe9sWJzOw8SXPUfVNRb5K0OLu9WNKLFfbyLd0yjXezacZV8WtX+fTn7t7xi6SbNfiN/P9K+rcqemjS1z9K+p/s8n7VvUl6VoNv6/5Pg++Ilki6UNIWSR9m1xd0UW//Jek9Se9qMFjjKurtnzT40fBdSbuyy81Vv3aJvjryunG4LBAER9ABQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBD/DzjJXcn1eldbAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_np = np.transpose(img.cpu().detach().numpy(), (1, 2, 0))\n",
    "plt.imshow(img_np, cmap = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1050,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 39200 into shape (1,28,28)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1050-586be8ce9b53>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrelevance_zb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mR_zb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrelevance_zb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'binary'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 39200 into shape (1,28,28)"
     ]
    }
   ],
   "source": [
    "relevance_zb = np.transpose(R_zb.cpu().detach().numpy().reshape(1, 28, 28), (1, 2, 0))\n",
    "plt.imshow(relevance_zb, cmap = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 915,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2502003b2e0>"
      ]
     },
     "execution_count": 915,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "relevance_ws = np.transpose(R_ws.cpu().detach().numpy().reshape(1, 28, 28), (1, 2, 0))\n",
    "plt.imshow(relevance_ws, cmap = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
